#!/usr/bin/env python3
import requests
import json
import time
import sys

def test_ollama_connection(base_url="http://localhost:11434"):
    """æ¸¬è©¦ Ollama æœå‹™é€£æ¥"""
    try:
        print(f"ğŸ”— Testing connection to {base_url}")
        response = requests.get(f"{base_url}/api/tags", timeout=10)
        if response.status_code == 200:
            print("âœ… Ollama service is accessible")
            models = response.json()
            print(f"ğŸ“‹ Available models: {len(models.get('models', []))}")
            for model in models.get('models', []):
                print(f"   - {model['name']}")
            return True
        else:
            print(f"âŒ Failed to connect: HTTP {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Connection failed: {e}")
        return False

def pull_model(model_name="llama3.2:1b", base_url="http://localhost:11434"):
    """æ‹‰å–æ¨¡å‹"""
    try:
        print(f"â¬‡ï¸ Pulling model: {model_name}")
        url = f"{base_url}/api/pull"
        payload = {"name": model_name}
        
        response = requests.post(url, json=payload, stream=True, timeout=300)
        
        if response.status_code == 200:
            print("âœ… Pull request sent successfully")
            
            # è™•ç†æµå¼éŸ¿æ‡‰
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line.decode('utf-8'))
                        if 'status' in data:
                            print(f"ğŸ“¥ {data['status']}")
                            if 'completed' in data and 'total' in data:
                                progress = (data['completed'] / data['total']) * 100
                                print(f"   Progress: {progress:.1f}%")
                        if data.get('status') == 'success':
                            print("âœ… Model pulled successfully!")
                            return True
                    except json.JSONDecodeError:
                        continue
        else:
            print(f"âŒ Pull failed: HTTP {response.status_code}")
            print(response.text)
            return False
            
    except Exception as e:
        print(f"âŒ Pull failed: {e}")
        return False

def test_model_generation(model_name="llama3.2:1b", base_url="http://localhost:11434"):
    """æ¸¬è©¦æ¨¡å‹ç”Ÿæˆ"""
    try:
        print(f"ğŸ§  Testing model generation with {model_name}")
        url = f"{base_url}/api/generate"
        payload = {
            "model": model_name,
            "prompt": "Hello, how are you?",
            "stream": False
        }
        
        response = requests.post(url, json=payload, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… Model generation successful!")
            print(f"ğŸ“ Response: {result.get('response', 'No response')}")
            return True
        else:
            print(f"âŒ Generation failed: HTTP {response.status_code}")
            print(response.text)
            return False
            
    except Exception as e:
        print(f"âŒ Generation failed: {e}")
        return False

def main():
    if len(sys.argv) > 1:
        base_url = sys.argv[1]
    else:
        base_url = "http://localhost:11434"
    
    print("ğŸš€ Ollama Service Test")
    print("=" * 50)
    
    # æ¸¬è©¦é€£æ¥
    if not test_ollama_connection(base_url):
        print("âŒ Cannot connect to Ollama service")
        sys.exit(1)
    
    # æ‹‰å–æ¨¡å‹
    model_name = "llama3.2:1b"  # ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹é€²è¡Œæ¸¬è©¦
    print(f"\nâ¬‡ï¸ Attempting to pull model: {model_name}")
    
    if pull_model(model_name, base_url):
        print("\nğŸ§  Testing model generation...")
        test_model_generation(model_name, base_url)
    else:
        print("âŒ Model pull failed, skipping generation test")
    
    print("\nğŸ Test completed")

if __name__ == "__main__":
    main()
