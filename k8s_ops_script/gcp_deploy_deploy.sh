#!/bin/bash

# è®¾ç½®å˜é‡
PROJECT_ID="ai-test-465504"
REGION="us-west4"  # é»˜è®¤ä½¿ç”¨å°æ¹¾æœºæˆ¿ï¼Œä½ å¯ä»¥æ”¹æˆå…¶ä»–åœ°åŒº
ZONE="us-west4-a"  # å…·ä½“çš„å¯ç”¨åŒº
CLUSTER_NAME="local-voice-ai-cluster"  # ä½ çš„é›†ç¾¤åç§°
GPU_NODE_POOL="gpu-pool"  # GPU èŠ‚ç‚¹æ± åç§°

# è®¾ç½® GKE è®¤è¯æ’ä»¶ç¯å¢ƒå˜é‡
export USE_GKE_GCLOUD_AUTH_PLUGIN=True

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ£€æŸ¥å¹¶å®‰è£… GKE è®¤è¯æ’ä»¶
echo "ğŸ”§ Checking GKE auth plugin..."
if ! command -v gke-gcloud-auth-plugin &> /dev/null; then
    echo "âŒ GKE auth plugin not found. Installing..."
    sudo apt-get update
    sudo apt-get install -y google-cloud-sdk-gke-gcloud-auth-plugin
    echo "âœ… GKE auth plugin installed"
else
    echo "âœ… GKE auth plugin is already installed"
fi

# ç¡®ä¿å·²ç™»å½•
echo "ğŸ” Ensuring GCP login..."
gcloud auth list --filter=status:ACTIVE --format="value(account)" || gcloud auth login

# è®¾ç½®é¡¹ç›®
echo "ğŸ“ Setting GCP project..."
gcloud config set project $PROJECT_ID

# è·å–é›†ç¾¤å‡­è¯
echo "ğŸ”‘ Getting cluster credentials..."
gcloud container clusters get-credentials $CLUSTER_NAME --zone $ZONE --project $PROJECT_ID

# éƒ¨ç½²åˆ° GKE
echo "ğŸš€ Deploying to GKE..."
cd k8s

# æ›´æ–°éƒ¨ç½²æ–‡ä»¶ä¸­çš„é•œåƒè·¯å¾„
echo "ğŸ”„ Updating image paths in deployment files..."
# å¤‡ä»½åŸå§‹æ–‡ä»¶
cp app-deployment.yaml app-deployment.yaml.bak
cp whisper-deployment.yaml whisper-deployment.yaml.bak

# æ›¿æ¢é•œåƒè·¯å¾„
sed -i "s|gcr.io/$PROJECT_ID/local-voice-ai:latest|$REGION-docker.pkg.dev/$PROJECT_ID/local-voice-ai-repo/local-voice-ai:latest|g" app-deployment.yaml
sed -i "s|gcr.io/$PROJECT_ID/whisper-service:latest|$REGION-docker.pkg.dev/$PROJECT_ID/local-voice-ai-repo/whisper-service:latest|g" whisper-deployment.yaml

# Apply PVC first
echo "ğŸ“¦ Applying PVC..."
kubectl apply -f hf-cache-pvc.yaml
kubectl apply -f ollama-pvc.yaml

# Apply ConfigMap
echo "âš™ï¸ Applying ConfigMap..."
kubectl apply -f configmap.yaml

# Apply deployments
echo "ğŸš€ Applying deployments..."
kubectl apply -f whisper-deployment.yaml
kubectl apply -f ollama-deployment.yaml
kubectl apply -f app-deployment.yaml

# Apply services
echo "ğŸ”Œ Applying services..."
kubectl apply -f whisper-service.yaml
kubectl apply -f ollama-service.yaml
kubectl apply -f app-service.yaml

# Apply ingress
echo "ğŸŒ Applying ingress..."
kubectl apply -f ingress.yaml

# Wait for pods to be ready
echo "â³ Waiting for pods to be ready..."
kubectl wait --for=condition=ready pod -l app=whisper --timeout=300s
kubectl wait --for=condition=ready pod -l app=ollama --timeout=300s
kubectl wait --for=condition=ready pod -l app=nextjs-app --timeout=300s

echo "âœ… Deployment completed!"

# Show pod status and GPU allocation
echo "ğŸ“Š Current pod status:"
kubectl get pods
echo "ğŸ® GPU allocation status:"
kubectl get pods -l app=whisper -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase,GPU:.spec.containers[0].resources.limits.nvidia\\.com/gpu
kubectl get pods -l app=ollama -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase,GPU:.spec.containers[0].resources.limits.nvidia\\.com/gpu

# Show service status
echo "ğŸ” Service status:"
kubectl get services

# Show ingress status
echo "ğŸŒ Ingress status:"
kubectl get ingress

# æ£€æŸ¥ GPU èŠ‚ç‚¹çŠ¶æ€
echo "ğŸ® GPU Node status:"
kubectl describe nodes | grep -A5 "nvidia.com/gpu"

echo "
ğŸ‰ Deployment complete! Your application should be accessible soon.
To get the external IP, run: kubectl get ingress

To verify GPU setup:
1. Check GPU node: kubectl describe node <node-name> | grep nvidia.com/gpu
2. Check Whisper pod logs: kubectl logs -l app=whisper
3. Check Ollama pod logs: kubectl logs -l app=ollama
4. Access health endpoint to verify GPU detection

ğŸ”— Port forwarding options:
To access services locally via port forwarding:
- NextJS App: kubectl port-forward service/nextjs-app 3000:3000
- Whisper Service: kubectl port-forward service/whisper-service 5001:5001
- Ollama Service: kubectl port-forward service/ollama-service 11434:11434

Then access:
- NextJS App: http://localhost:3000
- Whisper API: http://localhost:5001
- Ollama API: http://localhost:11434
"

# æ¢å¤éƒ¨ç½²æ–‡ä»¶åˆ°åŸå§‹çŠ¶æ€
echo "ğŸ”„ Restoring deployment files..."
if [ -f app-deployment.yaml.bak ]; then
    mv app-deployment.yaml.bak app-deployment.yaml
fi
if [ -f whisper-deployment.yaml.bak ]; then
    mv whisper-deployment.yaml.bak whisper-deployment.yaml
fi

echo -e "\n${GREEN}ğŸ‰ Deployment scripts created!${NC}"
echo "Available utility scripts:"
echo "   ./status.sh         - Check deployment status"
echo "   ./port_forward.sh   - Start port forwarding"
echo "   ./stop_port_forward.sh - Stop port forwarding" 