# ================================
# 本地語音 AI 環境配置
# ================================
# 重要：請複製此文件為 .env.local 並修改相應值
# 不要將實際的 .env 文件提交到版本控制中

# Ollama API endpoint - 請替換為您的 Ollama 服務地址
# 本地開發: http://localhost:11434
# 生產環境: 請設置為您的實際服務地址
OLLAMA_BASE_URL=http://localhost:11434

# Ollama model configuration
# 常用模型: llama3, gemma3:4b, qwen2.5:3b 等
OLLAMA_MODEL=gemma3:4b

# Whisper model configuration (tiny/base/small/medium/large)
# tiny: 最快但準確度較低
# small: 平衡速度和準確度 (推薦)
# medium: 更高準確度但較慢
# large: 最高準確度但最慢
WHISPER_MODEL=small

# Whisper service URL - 內部服務地址
WHISPER_SERVICE_URL=http://whisper-service:5001

# TTS service configuration (如果使用)
TTS_SERVICE_HOST=http://localhost:8000

# Next.js configuration
NODE_ENV=production

# ================================
# GCP 部署配置 (用於 Kubernetes 部署)
# ================================
# GCP 專案 ID - 請替換為您的實際專案 ID
GCP_PROJECT_ID=your-project-id

# GCP 區域設定
GCP_REGION=us-west4
GCP_ZONE=us-west4-a

# GKE 叢集設定
GCP_CLUSTER_NAME=local-voice-ai-cluster
GCP_GPU_NODE_POOL=gpu-pool

# Docker Registry 名稱
GCP_DOCKER_REGISTRY=local-voice-ai-repo

# ================================
# 安全性說明
# ================================
# 1. 請勿在代碼中硬編碼敏感資訊
# 2. 生產環境請使用密鑰管理服務
# 3. 定期輪換 API 密鑰和憑證
# 4. 確保 .env* 文件已加入 .gitignore 