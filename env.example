# Ollama API endpoint - customize this to your external Ollama service
OLLAMA_BASE_URL=https://site.ollama.lazyinwork.com

# Whisper model configuration (tiny/base/small/medium/large)
# tiny: 最快但準確度較低
# small: 平衡速度和準確度 (推薦)
# medium: 更高準確度但較慢
# large: 最高準確度但最慢
WHISPER_MODEL=small

# Next.js configuration
NODE_ENV=production 