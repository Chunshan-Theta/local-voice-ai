import axios from 'axios';
import FormData from 'form-data';
import fs from 'fs';

export interface ConversationMessage {
  role: 'user' | 'assistant';
  content: string;
}

const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || 'https://site.ollama.lazyinwork.com';
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || 'gemma3:1b';
const WHISPER_SERVICE_URL = process.env.WHISPER_SERVICE_URL || 'http://whisper-service:5001';

export async function whisperWithOllama(audioFilePath: string): Promise<string> {
  console.log('Processing audio file with local Python Whisper service:', audioFilePath);
  
  try {
    // Check if file exists
    if (!fs.existsSync(audioFilePath)) {
      throw new Error(`Audio file does not exist: ${audioFilePath}`);
    }

    const formData = new FormData();
    const audioBuffer = fs.readFileSync(audioFilePath);
    formData.append('audio', audioBuffer, {
      filename: 'audio.wav',
      contentType: 'audio/wav'
    });

    const response = await axios.post(`${WHISPER_SERVICE_URL}/transcribe`, formData, {
      headers: {
        ...formData.getHeaders(),
      },
      timeout: 120000, // 2 minutes timeout
      maxContentLength: 50 * 1024 * 1024, // 50MB max content length
      maxBodyLength: 50 * 1024 * 1024,    // 50MB max body length
    });

    const result = response.data;
    console.log('Whisper response:', result);

    if (result.transcript !== undefined) {
      return result.transcript || '';
    } else {
      throw new Error('No transcription result received');
    }
  } catch (error) {
    console.error('Whisper API error:', error);
    
    if (axios.isAxiosError(error)) {
      if (error.code === 'ECONNRESET') {
        throw new Error('Whisper service connection reset - audio file may be too large or processing took too long');
      } else if (error.code === 'ECONNREFUSED') {
        throw new Error('Could not connect to Whisper service - please check if the service is running');
      } else if (error.response) {
        throw new Error(`Whisper API error: ${error.response.data?.error || error.message}`);
      } else {
        throw new Error(`Network error: ${error.message}`);
      }
    }
    
    throw new Error('Voice recognition failed - please check Whisper service status');
  }
}

export async function chatWithOllama(
  userMessage: string, 
  conversationHistory: ConversationMessage[] = []
): Promise<string> {
  console.log('Sending message to Ollama:', userMessage);
  console.log('Conversation history length:', conversationHistory.length);
  
  // ç³»çµ±æç¤ºè© - è®“ AI è¡¨ç¾å¾—åƒçœŸäºº
  const systemPrompt = `ä½ æ˜¯ä¸€å€‹å‹å–„ã€è‡ªç„¶çš„èªéŸ³å°è©±å¤¥ä¼´ã€‚è«‹ç”¨éµå®ˆä»¥ä¸‹æ–¹å¼å›æ‡‰ï¼š

1. ä½¿ç”¨è‡ªç„¶ã€å£èªåŒ–çš„è¡¨é”æ–¹å¼ï¼Œå°±åƒçœŸäººå°è©±ä¸€æ¨£
2. å›æ‡‰è¦ç°¡æ½”æ˜ç­ï¼Œé€šå¸¸ 1-2 å¥è©±å³å¯
3. é©ç•¶ä½¿ç”¨èªæ°£è©å’Œè¡¨é”æƒ…æ„Ÿï¼Œå¦‚ï¼šå“¦ã€å•Šã€å‘¢ã€å§ã€çœŸçš„å—ã€å¤ªå¥½äº†ç­‰
4. æ ¹æ“šå°è©±å…§å®¹èª¿æ•´èªèª¿ï¼šè¼•é¬†ã€é—œå¿ƒã€èˆˆå¥®ã€åŒæƒ…ç­‰
5. å¯ä»¥é©ç•¶æå•ä¾†ä¿æŒå°è©±æµæš¢
6. é¿å…éæ–¼æ­£å¼æˆ–æ©Ÿæ¢°åŒ–çš„å›ç­”
7. å¦‚æœè©±é¡Œéœ€è¦ï¼Œå¯ä»¥åˆ†äº«ç›¸é—œçš„ç¶“é©—æˆ–çœ‹æ³•
8. ä¿æŒå‹å–„å’Œæ­£é¢çš„æ…‹åº¦
9. ä¸è¦æœ‰è¡¨æƒ…ç¬¦è™Ÿç­‰éå£èªå°è©±å…§å®¹ï¼Œä¾‹å¦‚ä¸è¦ä½¿ç”¨ã€ŒğŸ˜Šã€é€™æ¨£çš„è¡¨æƒ…ç¬¦è™Ÿ

è«‹è¨˜ä½ï¼Œé€™æ˜¯èªéŸ³å°è©±ï¼Œä½ çš„å›æ‡‰æœƒè¢«æœ—è®€å‡ºä¾†ï¼Œæ‰€ä»¥è¦è½èµ·ä¾†è‡ªç„¶æµæš¢ã€‚`;

  try {
    // æ§‹å»ºå®Œæ•´çš„å°è©±ä¸Šä¸‹æ–‡
    let fullPrompt = systemPrompt + "\n\n";
    
    // æ·»åŠ æœ€è¿‘çš„å°è©±æ­·å²ï¼ˆé™åˆ¶ç‚ºæœ€è¿‘ 6 è¼ªå°è©±é¿å…éé•·ï¼‰
    const recentHistory = conversationHistory.slice(-6);
    
    if (recentHistory.length > 0) {
      fullPrompt += "æœ€è¿‘çš„å°è©±æ­·å²ï¼š\n";
      recentHistory.forEach((msg) => {
        const speaker = msg.role === 'user' ? 'ç”¨æˆ¶' : 'åŠ©æ‰‹';
        fullPrompt += `${speaker}ï¼š${msg.content}\n`;
      });
      fullPrompt += "\n";
    }
    
    // æ·»åŠ ç•¶å‰ç”¨æˆ¶æ¶ˆæ¯
    fullPrompt += `ç¾åœ¨ç”¨æˆ¶èªªï¼š${userMessage}\n\nè«‹ä»¥è‡ªç„¶ã€çœŸäººèˆ¬çš„æ–¹å¼å›æ‡‰ï¼š`;

    const response = await axios.post(`${OLLAMA_BASE_URL}/api/generate`, {
      model: OLLAMA_MODEL,
      prompt: fullPrompt,
      stream: false,
      options: {
        temperature: 0.8,  // å¢åŠ ä¸€äº›å‰µé€ æ€§
        top_p: 0.9,       // ä¿æŒå›æ‡‰çš„å¤šæ¨£æ€§
        top_k: 40,        // é©ä¸­çš„è©å½™é¸æ“‡ç¯„åœ
      }
    }, {
      timeout: 30000, // 30ç§’è¶…æ™‚
    });

    if (response.data && response.data.response) {
      const reply = response.data.response.trim();
      console.log('Ollama response:', reply);
      return reply;
    } else {
      throw new Error('æœªæ”¶åˆ°æœ‰æ•ˆå›æ‡‰');
    }
  } catch (error) {
    console.error('Ollama API error:', error);
    
    if (axios.isAxiosError(error)) {
      if (error.response) {
        throw new Error(`Ollama API éŒ¯èª¤: ${error.response.data?.error || error.message}`);
      } else {
        throw new Error(`ç¶²è·¯éŒ¯èª¤: ${error.message}`);
      }
    }
    
    throw new Error('èŠå¤©æœå‹™å¤±æ•—');
  }
} 