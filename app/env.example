# Ollama API endpoint - 請替換為您的 Ollama 服務地址
# 本地開發: http://localhost:11434
# 生產環境: 請設置為您的實際服務地址
OLLAMA_BASE_URL=

# Ollama model configuration
# 常用模型: llama3, gemma3:4b, qwen2.5:3b 等
OLLAMA_MODEL=gemma3:12b


# Whisper service URL - 內部服務地址
WHISPER_SERVICE_URL=

# TTS
TTS_SERVICE_URL=
