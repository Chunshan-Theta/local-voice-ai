import { useState, useRef, useEffect } from 'react';
import { useRouter } from 'next/router';
import axios from 'axios';
import type { ConversationMessage } from '../../lib/ollama';
import { 
  createNoiseCalibrator, 
  createThresholdCalculator, 
  type NoiseCalibrator, 
  type ThresholdCalculator,
  NOISE_CALIBRATION_CONFIG 
} from '../../lib/noiseCalibrator';
import { 
  createTtsManager, 
  type TtsManager
} from '../../lib/ttsManager';
import { 
  createReplyManager, 
  type ReplyManager, 
  type Message,
  formatReplyError,
  isAudioValid
} from '../../lib/replyManager';

export default function Home() {
  const router = useRouter();
  
  // ç°¡åŒ–çš„ç‹€æ…‹ç®¡ç† - ç§»é™¤è‡ªå‹•æª¢æ¸¬ç›¸é—œç‹€æ…‹
  const [isListening, setIsListening] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [conversationStarted, setConversationStarted] = useState(false);
  
  // TTS ç›¸é—œç‹€æ…‹
  const [ttsEnabled] = useState(true);
  const [isSpeaking, setIsSpeaking] = useState(false);
  
  // éŸ³é‡ç›£æ§ç‹€æ…‹ï¼ˆåƒ…ç”¨æ–¼é¡¯ç¤ºï¼‰
  const [currentVolume, setCurrentVolume] = useState<number>(0);
  
  // ç°¡åŒ–çš„ refs ç®¡ç† - ç§»é™¤è‡ªå‹•æª¢æ¸¬ç›¸é—œçš„ refs
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioStreamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const ttsManagerRef = useRef<TtsManager | null>(null);
  const replyManagerRef = useRef<ReplyManager | null>(null);
  const volumeCheckIntervalRef = useRef<ReturnType<typeof setInterval> | null>(null);

  // ç°¡åŒ–çš„ refs
  const isListeningRef = useRef(false);
  const conversationStartedRef = useRef(false);
  const recordingStartTimeRef = useRef<number>(0);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // ç°¡åŒ–TTSç®¡ç†å™¨åˆå§‹åŒ–
  useEffect(() => {
    if (!ttsManagerRef.current) {
      ttsManagerRef.current = createTtsManager(
        {
          enabled: ttsEnabled,
          voice: null,
          rate: 1.5,
          volume: 0.8,
          pitch: 1.0
        },
        {
          onStart: (text, messageId) => {
            console.log('ğŸ”‡ TTSé–‹å§‹æ’­æ”¾');
            if (messageId) {
              setMessages(prev => prev.map(msg => 
                msg.id === messageId ? { ...msg, isPlaying: true } : { ...msg, isPlaying: false }
              ));
            }
          },
          onEnd: (messageId) => {
            console.log('âœ… TTSæ’­æ”¾å®Œæˆ');
            setMessages(prev => prev.map(msg => ({ ...msg, isPlaying: false })));
          },
          onError: (error, messageId) => {
            console.error('âŒ TTS éŒ¯èª¤:', error.error);
            setMessages(prev => prev.map(msg => ({ ...msg, isPlaying: false })));
          },
          onSpeakingChange: (speaking) => {
            setIsSpeaking(speaking);
          }
        }
      );
    }

    return () => {
      if (ttsManagerRef.current) {
        ttsManagerRef.current.destroy();
      }
      if (replyManagerRef.current) {
        replyManagerRef.current.destroy();
      }
      
      // æ¸…ç†éŸ³é »è³‡æº
      if (audioStreamRef.current) {
        audioStreamRef.current.getTracks().forEach(track => track.stop());
      }
      
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close();
      }
    };
  }, []);

  // åˆå§‹åŒ–å›è¦†ç®¡ç†å™¨
  useEffect(() => {
    if (!replyManagerRef.current) {
      replyManagerRef.current = createReplyManager(
        {
          maxHistoryLength: 10,
          timeout: 60000,
        },
        {
          onTranscriptionStart: (messageId) => {
            const userMessage: Message = {
              id: messageId,
              type: 'user',
              content: 'æ­£åœ¨è½‰éŒ„èªéŸ³...',
              timestamp: new Date(),
              isLoading: true,
            };
            setMessages(prev => [...prev, userMessage]);
          },
          onTranscriptionComplete: (messageId, transcript) => {
            setMessages(prev => prev.map(msg => 
              msg.id === messageId 
                ? { ...msg, content: transcript, isLoading: false }
                : msg
            ));
          },
          onReplyStart: (messageId) => {
            const aiMessage: Message = {
              id: messageId,
              type: 'ai',
              content: 'æ­£åœ¨æ€è€ƒå›è¦†...',
              timestamp: new Date(),
              isLoading: true,
            };
            setMessages(prev => [...prev, aiMessage]);
          },
          onReplyComplete: (messageId, reply) => {
            setMessages(prev => prev.map(msg => 
              msg.id === messageId 
                ? { ...msg, content: reply, isLoading: false }
                : msg
            ));
          },
          onError: (error, messageId) => {
            console.error('Reply éŒ¯èª¤:', error);
            setError(formatReplyError(error));
            
            // ç§»é™¤loadingä¸­çš„æ¶ˆæ¯
            if (messageId) {
              setMessages(prev => prev.filter(msg => msg.id !== messageId || !msg.isLoading));
            }
            
            // å¦‚æœæ˜¯èªéŸ³è½‰éŒ„éŒ¯èª¤ï¼Œæ›´æ–°ç”¨æˆ¶æ¶ˆæ¯ç‚ºéŒ¯èª¤æç¤ºï¼Œç„¶å¾Œ2ç§’å¾Œç§»é™¤
            if (error.includes('æœªè­˜åˆ¥åˆ°æœ‰æ•ˆèªéŸ³') && messageId) {
              setMessages(prev => prev.map(msg => 
                msg.id === messageId 
                  ? { ...msg, content: 'ğŸ”‡ æœªè­˜åˆ¥åˆ°æœ‰æ•ˆèªéŸ³ï¼Œè«‹é‡æ–°èªªè©±...', isLoading: false }
                  : msg
              ));
              
              // 2ç§’å¾Œç§»é™¤é€™å€‹éŒ¯èª¤æ¶ˆæ¯
              setTimeout(() => {
                setMessages(prev => prev.filter(msg => msg.id !== messageId));
              }, 2000);
            }
            
            // èªéŸ³è½‰éŒ„éŒ¯èª¤å¾Œä¸éœ€è¦ç‰¹æ®Šè™•ç†ï¼Œç”¨æˆ¶å¯ä»¥å†æ¬¡é»æ“ŠéŒ„éŸ³
            setTimeout(() => {
              // æ¸…é™¤éŒ¯èª¤ä¿¡æ¯
              setError(null);
            }, 3000); // 3ç§’å¾Œæ¸…é™¤éŒ¯èª¤
          },
          onSpeakReply: (text, messageId) => {
            if (ttsEnabled && text.trim()) {
              setTimeout(() => {
                speakText(text, messageId);
              }, 500);
            }
          }
        }
      );
    }

    return () => {
      if (replyManagerRef.current) {
        replyManagerRef.current.destroy();
      }
    };
  }, [ttsEnabled]);

  // åˆå§‹åŒ–éŸ³é »æµç”¨æ–¼éŸ³é‡ç›£æ§
  useEffect(() => {
    startVolumeMonitoring();
    
    return () => {
      stopVolumeMonitoring();
    };
  }, []);

  // è‡ªå‹•æ»¾å‹•åˆ°æœ€æ–°æ¶ˆæ¯
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  // TTS ç›¸é—œå‡½æ•¸
  const speakText = (text: string, messageId?: string) => {
    if (ttsManagerRef.current) {
      ttsManagerRef.current.speak(text, messageId);
    }
  };

  const stopSpeaking = () => {
    if (ttsManagerRef.current) {
      ttsManagerRef.current.stop();
    }
    setMessages(prev => prev.map(msg => ({ ...msg, isPlaying: false })));
  };

  // å‰µå»ºéŸ³é »æµ
  const createAudioStream = async () => {
    if (audioStreamRef.current) {
      audioStreamRef.current.getTracks().forEach(track => track.stop());
    }

    const stream = await navigator.mediaDevices.getUserMedia({ 
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
        sampleRate: 16000,
        channelCount: 1,
      } 
    });

    audioStreamRef.current = stream;
    return stream;
  };

  // è¨­ç½®éŸ³é »åˆ†æå™¨ç”¨æ–¼éŸ³é‡ç›£æ§
  const setupAudioAnalyser = (stream: MediaStream) => {
    if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
      audioContextRef.current = new AudioContext();
    }
    
    if (!analyserRef.current) {
      analyserRef.current = audioContextRef.current.createAnalyser();
      const source = audioContextRef.current.createMediaStreamSource(stream);
      source.connect(analyserRef.current);
      
      analyserRef.current.fftSize = 512;
      analyserRef.current.smoothingTimeConstant = 0.8;
    }
    
    return analyserRef.current;
  };

  // é–‹å§‹éŸ³é‡ç›£æ§ï¼ˆåƒ…ç”¨æ–¼é¡¯ç¤ºï¼‰
  const startVolumeMonitoring = async () => {
    try {
      let stream = audioStreamRef.current;
      if (!stream || !stream.active) {
        stream = await createAudioStream();
        setupAudioAnalyser(stream);
      }

      if (volumeCheckIntervalRef.current) {
        clearInterval(volumeCheckIntervalRef.current);
      }

      volumeCheckIntervalRef.current = setInterval(() => {
        if (!analyserRef.current) return;

        const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
        analyserRef.current.getByteFrequencyData(dataArray);
        
        const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
        setCurrentVolume(average);
      }, 100);
      
    } catch (error) {
      console.error('å•Ÿå‹•éŸ³é‡ç›£æ¸¬å¤±æ•—:', error);
    }
  };

  const stopVolumeMonitoring = () => {
    if (volumeCheckIntervalRef.current) {
      clearInterval(volumeCheckIntervalRef.current);
      volumeCheckIntervalRef.current = null;
    }
  };

  // æ‰‹å‹•æ§åˆ¶éŒ„éŸ³ - é»æ“Šé–‹å§‹ï¼Œå†æ¬¡é»æ“ŠçµæŸ
  const toggleRecording = async () => {
    if (isListening) {
      // çµæŸéŒ„éŸ³
      await stopRecording();
    } else {
      // é–‹å§‹éŒ„éŸ³
      await startRecording();
    }
  };

  const startRecording = async () => {
    try {
      setError(null);
      audioChunksRef.current = [];
      
      // å‰µå»ºæˆ–ä½¿ç”¨ç¾æœ‰éŸ³é »æµ
      let stream = audioStreamRef.current;
      if (!stream || !stream.active) {
        stream = await createAudioStream();
        setupAudioAnalyser(stream);
      }

      // å‰µå»ºMediaRecorder
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        if (audioChunksRef.current.length > 0) {
          await processAudio();
        }
      };

      mediaRecorder.start(100);
      setIsListening(true);
      isListeningRef.current = true;
      recordingStartTimeRef.current = Date.now();
      
      console.log('ğŸ¤ é–‹å§‹éŒ„éŸ³');
      
    } catch (err) {
      console.error('éŒ„éŸ³éŒ¯èª¤:', err);
      setError('ç„¡æ³•è¨ªå•éº¥å…‹é¢¨ï¼Œè«‹æª¢æŸ¥æ¬Šé™è¨­ç½®');
    }
  };

  const stopRecording = async () => {
    console.log('â¹ï¸ åœæ­¢éŒ„éŸ³');
    setIsListening(false);
    isListeningRef.current = false;
    
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
  };

  const startConversation = () => {
    console.log('âœ… é–‹å§‹å°è©±');
    setConversationStarted(true);
    conversationStartedRef.current = true;
  };

  const endConversation = () => {
    console.log('ğŸ›‘ çµæŸå°è©±');
    setConversationStarted(false);
    conversationStartedRef.current = false;
    
    if (isListening) {
      stopRecording();
    }
    stopSpeaking();
    setMessages([]);
    setError(null);
  };

  const processAudio = async () => {
    setLoading(true);
    setError(null);

    try {
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
      
      // æª¢æŸ¥éŒ„éŸ³æ™‚é•·
      const recordingDuration = Date.now() - recordingStartTimeRef.current;
      console.log(`ğŸ¤ éŒ„éŸ³æ™‚é•·: ${recordingDuration}ms`);
      
      // æœ€å°éŒ„éŸ³æ™‚é•·æª¢æŸ¥
      if (recordingDuration < 500) {
        console.log(`âš ï¸ éŒ„éŸ³æ™‚é–“éçŸ­ (<500ms)ï¼Œè«‹èªªè©±æ™‚é–“é•·ä¸€é»`);
        setError('éŒ„éŸ³æ™‚é–“éçŸ­ï¼Œè«‹èªªè©±æ™‚é–“é•·ä¸€é»');
        setLoading(false);
        return;
      }
      
      if (!isAudioValid(audioBlob)) {
        setLoading(false);
        return;
      }

      if (!replyManagerRef.current) {
        throw new Error('å›è¦†ç®¡ç†å™¨æœªåˆå§‹åŒ–');
      }

      // ä½¿ç”¨replyManagerè™•ç†éŸ³é »
      await replyManagerRef.current.processAudio(audioBlob, messages);

    } catch (err) {
      console.error('è™•ç†éŒ¯èª¤:', err);
    } finally {
      setLoading(false);
    }
  };

  const getVolumeBarColor = () => {
    if (isListening) return '#28a745'; // ç¶ è‰² - éŒ„éŸ³ä¸­
    if (isSpeaking) return '#9c27b0'; // ç´«è‰² - TTS æ’­æ”¾ä¸­
    return '#6c757d'; // ç°è‰² - å¾…æ©Ÿ
  };

  const getVolumePercentage = () => {
    const maxDisplayVolume = 100;
    return Math.min((currentVolume / maxDisplayVolume) * 100, 100);
  };

  const formatTime = (date: Date) => {
    return date.toLocaleTimeString('zh-TW', { 
      hour: '2-digit', 
      minute: '2-digit' 
    });
  };

  return (
    <div style={{ 
      display: 'flex', 
      flexDirection: 'column', 
      height: '100vh', 
      maxWidth: '800px', 
      margin: '0 auto',
      padding: '1rem'
    }}>
      {/* å°èˆªæŒ‰éˆ• */}
      <div style={{ 
        marginBottom: '1rem', 
        display: 'flex', 
        justifyContent: 'space-between', 
        alignItems: 'center' 
      }}>
        <button
          onClick={() => router.push('/voice-setup')}
          style={{
            padding: '0.5rem 1rem',
            fontSize: '0.9rem',
            backgroundColor: '#6c757d',
            color: 'white',
            border: 'none',
            borderRadius: '6px',
            cursor: 'pointer',
            display: 'none',
            alignItems: 'center',
            gap: '0.5rem'
          }}
        >
          âš™ï¸ èªéŸ³è¨­å®š
        </button>
      </div>
      
      <h1>æ‰‹å‹•èªéŸ³ AI åŠ©æ‰‹ ğŸ¤</h1>
      <p style={{ color: '#666', marginBottom: '1rem' }}>
        é»æ“Šå¼èªéŸ³å°è©±æ¨¡å¼ã€‚é»æ“Šé–‹å§‹éŒ„éŸ³ï¼Œå†æ¬¡é»æ“ŠçµæŸéŒ„éŸ³ï¼ŒAI å°‡è‡ªå‹•é€²è¡ŒèªéŸ³è½‰éŒ„ã€å›è¦†ç”Ÿæˆå’ŒèªéŸ³æ’­æ”¾ã€‚
      </p>
      
      {/* éŸ³é‡ç›£æ§ */}
      <div style={{ marginBottom: '1rem', padding: '1rem', backgroundColor: '#f8f9fa', borderRadius: '8px' }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', marginBottom: '0.5rem' }}>
          <span style={{ fontSize: '0.9rem', color: '#666' }}>éŸ³é‡ç›£æ§</span>
          <span style={{ fontSize: '0.8rem', color: '#666' }}>
            ç•¶å‰: {currentVolume.toFixed(1)}
          </span>
        </div>
        <div style={{ 
          width: '100%', 
          height: '8px', 
          backgroundColor: '#e9ecef', 
          borderRadius: '4px',
          overflow: 'hidden'
        }}>
          <div style={{
            width: `${getVolumePercentage()}%`,
            height: '100%',
            backgroundColor: getVolumeBarColor(),
            transition: 'all 0.1s ease'
          }} />
        </div>
        <div style={{ fontSize: '0.8rem', color: '#666', marginTop: '0.5rem' }}>
          {isListening && (
            <span style={{ color: '#28a745' }}>ğŸ¤ éŒ„éŸ³ä¸­</span>
          )}
          {isSpeaking && !isListening && (
            <span style={{ color: '#9c27b0' }}>ğŸ—£ï¸ TTSç”Ÿæˆä¸­</span>
          )}
          {!isSpeaking && !isListening && conversationStarted && (
            <span style={{ color: '#007bff' }}>ğŸ”Š ç­‰å¾…éŒ„éŸ³</span>
          )}
          {!conversationStarted && (
            <span style={{ color: '#6c757d' }}>ğŸ“Š éŸ³é‡ç›£æ¸¬ä¸­</span>
          )}
        </div>
      </div>

      {/* æ§åˆ¶æŒ‰éˆ• */}
      <div style={{ marginBottom: '1rem' }}>
        {!conversationStarted ? (
          <button
            onClick={startConversation}
            disabled={loading}
            style={{
              padding: '1rem 2rem',
              fontSize: '1.2rem',
              backgroundColor: loading ? '#6c757d' : '#28a745',
              color: 'white',
              border: 'none',
              borderRadius: '8px',
              cursor: loading ? 'not-allowed' : 'pointer',
            }}
          >
            ğŸ™ï¸ é–‹å§‹å°è©±
          </button>
        ) : (
          <div style={{ display: 'flex', gap: '1rem', alignItems: 'center' }}>
            
            {/* éŒ„éŸ³æ§åˆ¶æŒ‰éˆ• */}
            <button
              onClick={toggleRecording}
              disabled={loading || isSpeaking}
              style={{
                padding: '1rem 1.5rem',
                fontSize: '1.2rem',
                backgroundColor: loading || isSpeaking ? '#6c757d' : isListening ? '#dc3545' : '#007bff',
                color: 'white',
                border: 'none',
                borderRadius: '8px',
                cursor: loading || isSpeaking ? 'not-allowed' : 'pointer',
                minWidth: '160px'
              }}
            >
              {loading ? 'â³ è™•ç†ä¸­...' : isListening ? 'â¹ï¸ åœæ­¢éŒ„éŸ³' : 'ğŸ¤ é–‹å§‹éŒ„éŸ³'}
            </button>
            
            <button
              onClick={endConversation}
              style={{
                padding: '1rem 1.5rem',
                fontSize: '1rem',
                backgroundColor: '#6c757d',
                color: 'white',
                border: 'none',
                borderRadius: '8px',
                cursor: 'pointer',
              }}
            >
              ğŸ›‘ çµæŸå°è©±
            </button>

          </div>
        )}
        
        {isListening && (
          <div style={{ 
            marginTop: '1rem', 
            padding: '0.5rem', 
            backgroundColor: '#d4edda', 
            borderRadius: '4px',
            fontSize: '0.9rem',
            color: '#155724'
          }}>
            ğŸ¤ éŒ„éŸ³ä¸­ - é»æ“Šã€Œåœæ­¢éŒ„éŸ³ã€æŒ‰éˆ•çµæŸéŒ„éŸ³ä¸¦ç™¼é€...
          </div>
        )}

        {conversationStarted && !isListening && !loading && !isSpeaking && (
          <div style={{ 
            marginTop: '1rem', 
            padding: '0.5rem', 
            backgroundColor: '#d1ecf1', 
            borderRadius: '4px',
            fontSize: '0.9rem',
            color: '#0c5460'
          }}>
            ğŸ’¬ é»æ“Šã€Œé–‹å§‹éŒ„éŸ³ã€æŒ‰éˆ•ä¾†éŒ„è£½æ‚¨çš„èªéŸ³æ¶ˆæ¯
          </div>
        )}

        {isSpeaking && (
          <div style={{ 
            marginTop: '1rem', 
            padding: '0.5rem', 
            backgroundColor: '#e2e3e5', 
            borderRadius: '4px',
            fontSize: '0.9rem',
            color: '#383d41'
          }}>
            ğŸ—£ï¸ AI æ­£åœ¨å›è¦†ä¸­ï¼Œè«‹ç­‰å¾…æ’­æ”¾å®Œæˆå¾Œå†éŒ„éŸ³...
          </div>
        )}
      </div>

      {error && (
        <div style={{
          padding: '1rem',
          backgroundColor: (error.includes('æœªè­˜åˆ¥åˆ°æœ‰æ•ˆèªéŸ³') || error.includes('éŒ„éŸ³æ™‚é–“éçŸ­')) ? '#fff3cd' : '#f8d7da',
          color: (error.includes('æœªè­˜åˆ¥åˆ°æœ‰æ•ˆèªéŸ³') || error.includes('éŒ„éŸ³æ™‚é–“éçŸ­')) ? '#856404' : '#721c24',
          borderRadius: '4px',
          marginBottom: '1rem',
          display: 'flex',
          alignItems: 'center',
          gap: '0.5rem'
        }}>
          {error.includes('æœªè­˜åˆ¥åˆ°æœ‰æ•ˆèªéŸ³') ? (
            <>
              ğŸ¤ {error}ï¼Œè«‹é‡æ–°éŒ„éŸ³...
              <span style={{ fontSize: '0.8rem', opacity: 0.7, marginLeft: 'auto' }}>
                (3ç§’å¾Œè‡ªå‹•æ¸…é™¤)
              </span>
            </>
          ) : error.includes('éŒ„éŸ³æ™‚é–“éçŸ­') ? (
            <>
              â±ï¸ {error}
              <span style={{ fontSize: '0.8rem', opacity: 0.7, marginLeft: 'auto' }}>
                (3ç§’å¾Œè‡ªå‹•æ¸…é™¤)
              </span>
            </>
          ) : (
            <>éŒ¯èª¤ï¼š{error}</>
          )}
        </div>
      )}

      {/* èŠå¤©è¨˜éŒ„å€åŸŸ */}
      <div style={{ 
        flex: 1, 
        backgroundColor: '#f8f9fa', 
        borderRadius: '8px', 
        padding: '1rem', 
        overflow: 'auto',
        display: 'flex',
        flexDirection: 'column',
        gap: '1rem'
      }}>
        {messages.length === 0 && conversationStarted && (
          <div style={{ 
            textAlign: 'center', 
            color: '#666', 
            fontStyle: 'italic',
            marginTop: '2rem'
          }}>
            ğŸ¤ é»æ“Šã€Œé–‹å§‹éŒ„éŸ³ã€æŒ‰éˆ•ä¾†é€²è¡Œå°è©±...
          </div>
        )}

        {messages.map((message) => (
          <div
            key={message.id}
            style={{
              display: 'flex',
              justifyContent: message.type === 'user' ? 'flex-end' : 'flex-start',
              marginBottom: '1rem'
            }}
          >
            <div
              style={{
                maxWidth: '70%',
                padding: '1rem',
                borderRadius: '12px',
                backgroundColor: message.type === 'user' ? '#007bff' : '#e9ecef',
                color: message.type === 'user' ? 'white' : '#333',
                position: 'relative',
                opacity: message.isLoading ? 0.7 : 1,
              }}
            >
              <div style={{ 
                fontSize: '0.8rem', 
                opacity: 0.8, 
                marginBottom: '0.5rem',
                display: 'flex',
                alignItems: 'center',
                gap: '0.5rem'
              }}>
                <span>{message.type === 'user' ? 'ğŸ—£ï¸ ä½ ' : 'ğŸ¤– AI'}</span>
                <span>{formatTime(message.timestamp)}</span>
                {message.isLoading && <span>â³</span>}
                {message.isPlaying && <span>ğŸ”Š</span>}
                
                {/* AIæ¶ˆæ¯çš„æ’­æ”¾æŒ‰éˆ• */}
                {message.type === 'ai' && !message.isLoading && message.content.trim() && (
                  <button
                    onClick={() => {
                      if (message.isPlaying) {
                        stopSpeaking();
                      } else {
                        speakText(message.content, message.id);
                      }
                    }}
                    style={{
                      padding: '0.2rem 0.4rem',
                      fontSize: '0.7rem',
                      backgroundColor: message.isPlaying ? '#dc3545' : '#28a745',
                      color: 'white',
                      border: 'none',
                      borderRadius: '3px',
                      cursor: 'pointer',
                      opacity: 0.8,
                    }}
                  >
                    {message.isPlaying ? 'ğŸ”‡' : 'ğŸ”Š'}
                  </button>
                )}
              </div>
              <div style={{ fontSize: '1rem', lineHeight: '1.4' }}>
                {message.content}
              </div>
            </div>
          </div>
        ))}
        <div ref={messagesEndRef} />
      </div>

      <style jsx>{`
        @keyframes pulse {
          0% { transform: scale(1); }
          50% { transform: scale(1.05); }
          100% { transform: scale(1); }
        }
      `}</style>
    </div>
  );
}