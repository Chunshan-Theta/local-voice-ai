import { useState, useRef, useEffect } from 'react';
import axios from 'axios';
import type { ConversationMessage } from '../lib/ollama';

interface Message {
  id: string;
  type: 'user' | 'ai';
  content: string;
  timestamp: Date;
  isLoading?: boolean;
  isPlaying?: boolean;
}

export default function Home() {
  const [isListening, setIsListening] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [conversationStarted, setConversationStarted] = useState(false);
  
  // TTS ç›¸é—œç‹€æ…‹
  const [ttsEnabled, setTtsEnabled] = useState(true);
  const [ttsVoice, setTtsVoice] = useState<SpeechSynthesisVoice | null>(null);
  const [ttsRate, setTtsRate] = useState(1.0);
  const [ttsVolume, setTtsVolume] = useState(0.8);
  const [availableVoices, setAvailableVoices] = useState<SpeechSynthesisVoice[]>([]);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [ttsVolumeLevel, setTtsVolumeLevel] = useState<number>(0); // ç›£æ§TTSå¯¦éš›éŸ³é‡
  const [ttsStartTime, setTtsStartTime] = useState<number>(0); // TTSé–‹å§‹æ™‚é–“
  
  // ç’°å¢ƒéŸ³æª¢æ¸¬ç›¸é—œç‹€æ…‹
  const [isCalibrating, setIsCalibrating] = useState(false);
  const [baselineNoise, setBaselineNoise] = useState<number>(10);
  const [currentVolume, setCurrentVolume] = useState<number>(0);
  const [calibrationProgress, setCalibrationProgress] = useState<number>(0);
  const [hasDetectedVoice, setHasDetectedVoice] = useState(false);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const calibrationDataRef = useRef<number[]>([]);
  const volumeCheckIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const currentUtteranceRef = useRef<SpeechSynthesisUtterance | null>(null);
  const ttsVolumeSamplesRef = useRef<number[]>([]);
  const previousVolumeRef = useRef<number>(0);
  const volumeChangeCountRef = useRef<number>(0);

  // èªéŸ³æ´»å‹•æª¢æ¸¬åƒæ•¸
  const SILENCE_DURATION = 2000; // 2ç§’éœéŸ³å¾Œè‡ªå‹•ç™¼é€
  const MIN_RECORDING_TIME = 1000; // æœ€çŸ­éŒ„éŸ³æ™‚é–“ 1ç§’
  const CALIBRATION_DURATION = 3000; // 3ç§’æ ¡æº–æ™‚é–“

  // æ–°å¢ï¼šæŒçºŒçš„éŸ³é »æµç®¡ç†
  const audioStreamRef = useRef<MediaStream | null>(null);

  const isListeningRef = useRef(false);
  const hasDetectedVoiceRef = useRef(false);
  const baselineNoiseRef = useRef(10);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // åˆå§‹åŒ– TTS èªéŸ³åˆ—è¡¨
  useEffect(() => {
    // ç¢ºä¿åœ¨ç€è¦½å™¨ç’°å¢ƒä¸­é‹è¡Œ
    if (typeof window === 'undefined' || !speechSynthesis) return;

    const loadVoices = () => {
      const voices = speechSynthesis.getVoices();
      setAvailableVoices(voices);
      
      // å„ªå…ˆé¸æ“‡ä¸­æ–‡èªéŸ³
      const chineseVoice = voices.find(voice => 
        voice.lang.includes('zh') || 
        voice.lang.includes('cmn') ||
        voice.name.includes('Chinese') ||
        voice.name.includes('ä¸­æ–‡')
      );
      
      if (chineseVoice) {
        setTtsVoice(chineseVoice);
        console.log('ğŸ—£ï¸ é¸æ“‡ä¸­æ–‡èªéŸ³:', chineseVoice.name, chineseVoice.lang);
      } else if (voices.length > 0) {
        setTtsVoice(voices[0]);
        console.log('ğŸ—£ï¸ é¸æ“‡é è¨­èªéŸ³:', voices[0].name, voices[0].lang);
      }
    };

    // èªéŸ³åˆ—è¡¨å¯èƒ½éœ€è¦æ™‚é–“è¼‰å…¥
    if (speechSynthesis.getVoices().length === 0) {
      speechSynthesis.addEventListener('voiceschanged', loadVoices);
    } else {
      loadVoices();
    }

    return () => {
      if (speechSynthesis) {
        speechSynthesis.removeEventListener('voiceschanged', loadVoices);
      }
    };
  }, []);

  // ç›£è½èªéŸ³åˆæˆç‹€æ…‹
  useEffect(() => {
    // ç¢ºä¿åœ¨ç€è¦½å™¨ç’°å¢ƒä¸­é‹è¡Œ
    if (typeof window === 'undefined' || !speechSynthesis) return;

    const checkSpeaking = () => {
      setIsSpeaking(speechSynthesis.speaking);
    };

    const interval = setInterval(checkSpeaking, 100);
    return () => clearInterval(interval);
  }, []);

  // è¨ˆç®—å‹•æ…‹é–¾å€¼ - ä½¿ç”¨ ref ç¢ºä¿æœ€æ–°å€¼
  const getSilenceThreshold = () => baselineNoiseRef.current + 0.5; // é€²ä¸€æ­¥é™ä½
  const getVoiceThreshold = () => {
    // å¦‚æœTTSæ­£åœ¨æ’­æ”¾ï¼Œæ ¹æ“šå¯¦éš›TTSéŸ³é‡å‹•æ…‹è¨­ç½®é–¾å€¼
    if (typeof window !== 'undefined' && speechSynthesis && speechSynthesis.speaking) {
      // TTSå‰›é–‹å§‹æ’­æ”¾çš„å‰1ç§’ä½¿ç”¨è¼ƒé«˜é–¾å€¼é¿å…åˆå§‹æ³¢å‹•èª¤åˆ¤
      const timeSinceStart = Date.now() - ttsStartTime;
      if (timeSinceStart < 1000) {
        return baselineNoiseRef.current + 20; // å‰1ç§’ä½¿ç”¨è¼ƒé«˜é–¾å€¼
      }
      
      // å‹•æ…‹è¨ˆç®—ï¼šåŸºæ–¼æ”¶é›†åˆ°çš„TTSéŸ³é‡æ•¸æ“š
      if (ttsVolumeSamplesRef.current.length > 8) {
        const avgTtsVolume = ttsVolumeSamplesRef.current.reduce((sum, vol) => sum + vol, 0) / ttsVolumeSamplesRef.current.length;
        const maxTtsVolume = Math.max(...ttsVolumeSamplesRef.current);
        // ä½¿ç”¨å¹³è¡¡çš„å€æ•¸ï¼šå–å¹³å‡å€¼çš„1.4å€æˆ–æœ€å¤§å€¼çš„1.2å€ï¼Œé¸è¼ƒå¤§è€…
        const balancedThreshold = Math.max(
          avgTtsVolume * 1.4,
          maxTtsVolume * 1.2,
          baselineNoiseRef.current + 30
        );
        return balancedThreshold;
      }
      // å¦‚æœé‚„æ²’æ”¶é›†åˆ°è¶³å¤ æ•¸æ“šï¼Œä½¿ç”¨ä¸­ç­‰å›ºå®šå€¼
      return baselineNoiseRef.current + 15;
    }
    return baselineNoiseRef.current + 1;   // æ­£å¸¸æƒ…æ³ä¸‹çš„èªéŸ³é–¾å€¼
  };

  // ç•¶æœ‰æ–°çš„ AI å›æ‡‰æ™‚ï¼Œè‡ªå‹•é‡æ–°é–‹å§‹éŒ„éŸ³ï¼ˆå³ä½¿TTSåœ¨æ’­æ”¾ä¹Ÿé–‹å§‹éŒ„éŸ³ç›£è½ï¼‰
  useEffect(() => {
    if (messages.length > 0 && conversationStarted && !loading && !isListening) {
      const lastMessage = messages[messages.length - 1];
      if (lastMessage.type === 'ai' && !lastMessage.isLoading) {
        const timer = setTimeout(() => {
          startListening();
        }, 1000);
        
        return () => clearTimeout(timer);
      }
    }
  }, [messages, conversationStarted, loading, isListening]);

  // è‡ªå‹•æ»¾å‹•åˆ°æœ€æ–°æ¶ˆæ¯
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  // TTS ç›¸é—œå‡½æ•¸
  const speakText = (text: string, messageId?: string) => {
    // ç¢ºä¿åœ¨ç€è¦½å™¨ç’°å¢ƒä¸­é‹è¡Œ
    if (typeof window === 'undefined' || !speechSynthesis) return;

    // åœæ­¢ç•¶å‰æ’­æ”¾
    speechSynthesis.cancel();
    
    if (!text.trim()) return;

    const utterance = new SpeechSynthesisUtterance(text);
    currentUtteranceRef.current = utterance;

    // è¨­ç½®èªéŸ³åƒæ•¸
    if (ttsVoice) {
      utterance.voice = ttsVoice;
    }
    utterance.rate = ttsRate;
    utterance.volume = ttsVolume;
    utterance.pitch = 1;

    // äº‹ä»¶ç›£è½
    utterance.onstart = () => {
      console.log('ğŸ—£ï¸ é–‹å§‹æœ—è®€:', text.substring(0, 50) + '...');
      console.log('ğŸ”‡ TTSé–‹å§‹ï¼ŒèªéŸ³æª¢æ¸¬å°‡ä½¿ç”¨å‹•æ…‹é–¾å€¼');
      setTtsStartTime(Date.now()); // è¨˜éŒ„TTSé–‹å§‹æ™‚é–“
      // é‡ç½®éŸ³é‡è®ŠåŒ–è¨ˆæ•¸
      volumeChangeCountRef.current = 0;
      previousVolumeRef.current = 0;
      if (messageId) {
        setMessages(prev => prev.map(msg => 
          msg.id === messageId ? { ...msg, isPlaying: true } : { ...msg, isPlaying: false }
        ));
      }
    };

    utterance.onend = () => {
      const avgTtsVolume = ttsVolumeSamplesRef.current.length > 0 
        ? (ttsVolumeSamplesRef.current.reduce((sum, vol) => sum + vol, 0) / ttsVolumeSamplesRef.current.length).toFixed(1)
        : 'N/A';
      console.log(`âœ… æœ—è®€å®Œæˆï¼Œæ”¶é›†åˆ°${ttsVolumeSamplesRef.current.length}å€‹éŸ³é‡æ¨£æœ¬ï¼Œå¹³å‡TTSéŸ³é‡: ${avgTtsVolume}`);
      console.log('ğŸ”„ èªéŸ³æª¢æ¸¬é–¾å€¼æ¢å¾©æ­£å¸¸:', baselineNoiseRef.current + 1);
      setMessages(prev => prev.map(msg => ({ ...msg, isPlaying: false })));
      currentUtteranceRef.current = null;
    };

    utterance.onerror = (event) => {
      console.error('âŒ TTS éŒ¯èª¤:', event.error);
      setMessages(prev => prev.map(msg => ({ ...msg, isPlaying: false })));
      currentUtteranceRef.current = null;
    };

    speechSynthesis.speak(utterance);
  };

  const stopSpeaking = () => {
    // ç¢ºä¿åœ¨ç€è¦½å™¨ç’°å¢ƒä¸­é‹è¡Œ
    if (typeof window === 'undefined' || !speechSynthesis) return;

    speechSynthesis.cancel();
    setMessages(prev => prev.map(msg => ({ ...msg, isPlaying: false })));
    currentUtteranceRef.current = null;
  };

  // å‰µå»ºæŒçºŒçš„éŸ³é »æµ - æ ¡æº–å’ŒéŒ„éŸ³å…±ç”¨
  const createAudioStream = async () => {
    if (audioStreamRef.current) {
      // å¦‚æœå·²ç¶“æœ‰æµï¼Œå…ˆæ¸…ç†
      audioStreamRef.current.getTracks().forEach(track => track.stop());
    }

    const stream = await navigator.mediaDevices.getUserMedia({ 
      audio: {
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false,
      } 
    });

    audioStreamRef.current = stream;
    streamRef.current = stream;
    
    console.log('ğŸ¤ å‰µå»ºçµ±ä¸€éŸ³é »æµï¼Œè»Œé“è¨­ç½®:', stream.getAudioTracks()[0].getSettings());
    return stream;
  };

  // è¨­ç½®éŸ³é »åˆ†æå™¨ - æ ¡æº–å’ŒéŒ„éŸ³å…±ç”¨
  const setupAudioAnalyser = (stream: MediaStream) => {
    // åªæœ‰åœ¨æ²’æœ‰éŸ³é »ä¸Šä¸‹æ–‡æˆ–ä¸Šä¸‹æ–‡å·²é—œé–‰æ™‚æ‰å‰µå»ºæ–°çš„
    if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
      console.log('ğŸ”„ å‰µå»ºæ–°çš„éŸ³é »ä¸Šä¸‹æ–‡');
      audioContextRef.current = new AudioContext();
    } else {
      console.log('âœ… å¾©ç”¨ç¾æœ‰éŸ³é »ä¸Šä¸‹æ–‡');
    }
    
    // åªæœ‰åœ¨æ²’æœ‰åˆ†æå™¨æ™‚æ‰å‰µå»ºæ–°çš„
    if (!analyserRef.current) {
      console.log('ğŸ”„ å‰µå»ºæ–°çš„éŸ³é »åˆ†æå™¨');
      analyserRef.current = audioContextRef.current.createAnalyser();
      const source = audioContextRef.current.createMediaStreamSource(stream);
      source.connect(analyserRef.current);
      
      analyserRef.current.fftSize = 512;
      analyserRef.current.smoothingTimeConstant = 0.8;
      
      console.log('ğŸ”Š éŸ³é »åˆ†æå™¨è¨­ç½®å®Œæˆï¼Œé »ç‡æ•¸æ“šå¤§å°:', analyserRef.current.frequencyBinCount);
    } else {
      console.log('âœ… å¾©ç”¨ç¾æœ‰éŸ³é »åˆ†æå™¨');
    }
    
    return analyserRef.current;
  };

  // ç’°å¢ƒéŸ³æ ¡æº– - ä½¿ç”¨çµ±ä¸€éŸ³é »æµ
  const calibrateEnvironmentalNoise = async () => {
    try {
      setIsCalibrating(true);
      setCalibrationProgress(0);
      calibrationDataRef.current = [];
      
      // æ ¡æº–æ™‚å¿…é ˆåœæ­¢TTSæ’­æ”¾ï¼Œå› ç‚ºéœ€è¦å®‰éœç’°å¢ƒ
      stopSpeaking();
      
      // å‰µå»ºçµ±ä¸€éŸ³é »æµ
      const stream = await createAudioStream();
      const analyser = setupAudioAnalyser(stream);

      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      
      const calibrationStart = Date.now();
      const calibrationInterval = setInterval(() => {
        analyser.getByteFrequencyData(dataArray);
        const sum = Array.from(dataArray).reduce((a, b) => a + b, 0);
        const average = sum / dataArray.length;
        
        calibrationDataRef.current.push(average);
        setCurrentVolume(average);
        
        const elapsed = Date.now() - calibrationStart;
        const progress = Math.min((elapsed / CALIBRATION_DURATION) * 100, 100);
        setCalibrationProgress(progress);
        
        if (elapsed >= CALIBRATION_DURATION) {
          clearInterval(calibrationInterval);
          
          // è¨ˆç®—ç’°å¢ƒéŸ³åŸºæº–
          const samples = calibrationDataRef.current;
          const mean = samples.reduce((sum, val) => sum + val, 0) / samples.length;
          const baseline = Math.max(mean, 10);
          
          setBaselineNoise(baseline);
          baselineNoiseRef.current = baseline; // åŒæ™‚æ›´æ–° ref
          console.log(`âœ… ç’°å¢ƒéŸ³æ ¡æº–å®Œæˆ: ${baseline.toFixed(1)} (ä½¿ç”¨çµ±ä¸€éŸ³è»Œ)ï¼ŒèªéŸ³é–¾å€¼: ${(baseline + 1).toFixed(1)}`);
          
          setIsCalibrating(false);
          setCurrentVolume(0);
          
          // é‡è¦ï¼šæ ¡æº–å®Œæˆå¾Œä¸é—œé–‰éŸ³é »æµï¼Œç¹¼çºŒç”¨æ–¼éŒ„éŸ³
        }
      }, 50);
      
    } catch (err) {
      console.error('æ ¡æº–éŒ¯èª¤:', err);
      setError('æ ¡æº–å¤±æ•—ï¼Œå°‡ä½¿ç”¨é è¨­å€¼');
      setIsCalibrating(false);
    }
  };

  const startListening = async () => {
    try {
      setError(null);
      audioChunksRef.current = [];
      setHasDetectedVoice(false);
      hasDetectedVoiceRef.current = false;
      
      // æ³¨æ„ï¼šä¸å†è‡ªå‹•åœæ­¢TTSï¼Œå…è¨±TTSæ’­æ”¾æ™‚é€²è¡ŒéŒ„éŸ³ç›£è½
      
      console.log('ğŸ¤ é–‹å§‹éŒ„éŸ³ - æª¢æŸ¥ç¾æœ‰è³‡æºï¼ˆTTSå¯èƒ½ä»åœ¨æ’­æ”¾ï¼‰');
      
      // æª¢æŸ¥æ˜¯å¦å·²æœ‰éŸ³é »æµï¼ˆæ ¡æº–æ™‚å‰µå»ºçš„ï¼‰
      let stream = audioStreamRef.current;
      
      if (!stream || !stream.active) {
        console.log('âš ï¸ æ²’æœ‰æ´»èºéŸ³é »æµï¼Œé‡æ–°å‰µå»º');
        stream = await createAudioStream();
        setupAudioAnalyser(stream);
      } else {
        console.log('âœ… ä½¿ç”¨æ ¡æº–æ™‚çš„éŸ³é »æµ');
        
        // æª¢æŸ¥éŸ³é »ä¸Šä¸‹æ–‡æ˜¯å¦é‚„æ´»èº
        if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
          console.log('ğŸ”„ éŸ³é »ä¸Šä¸‹æ–‡å·²é—œé–‰ï¼Œé‡æ–°è¨­ç½®åˆ†æå™¨');
          setupAudioAnalyser(stream);
        } else {
          console.log('âœ… éŸ³é »ä¸Šä¸‹æ–‡å’Œåˆ†æå™¨éƒ½å¯ç”¨');
        }
      }

      // ä½¿ç”¨ç¾æœ‰çš„éŸ³é »æµé€²è¡ŒéŒ„éŸ³
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        if (audioChunksRef.current.length > 0) {
          await processAudio();
        }
      };

      mediaRecorder.start(100);
      setIsListening(true);
      isListeningRef.current = true;
      
      if (!conversationStarted) {
        setConversationStarted(true);
      }
      
      // å•Ÿå‹•éŸ³é‡ç›£æ§ï¼ˆä½¿ç”¨ç›¸åŒçš„åˆ†æå™¨ï¼‰
      startVolumeMonitoring();
      
      console.log('ğŸ¤ éŒ„éŸ³å’ŒéŸ³é‡ç›£æ§å·²å•Ÿå‹• - çµ±ä¸€éŸ³è»Œæ¶æ§‹');
      
    } catch (err) {
      console.error('éŒ„éŸ³éŒ¯èª¤:', err);
      setError('ç„¡æ³•è¨ªå•éº¥å…‹é¢¨ï¼Œè«‹æª¢æŸ¥æ¬Šé™è¨­ç½®');
    }
  };

  const stopListening = () => {
    console.log('ğŸ›‘ stopListening è¢«èª¿ç”¨');
    
    setIsListening(false);
    isListeningRef.current = false;
    setCurrentVolume(0);
    setHasDetectedVoice(false);
    hasDetectedVoiceRef.current = false;
    
    stopVolumeMonitoring();
    
    if (silenceTimerRef.current) {
      console.log('ğŸ• æ¸…ç†éœéŸ³è¨ˆæ™‚å™¨:', silenceTimerRef.current);
      clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }
    
    // é‡è¦ï¼šä¸é—œé–‰éŸ³é »ä¸Šä¸‹æ–‡å’ŒéŸ³é »æµï¼Œä¿æŒæŒçºŒå¯ç”¨
    console.log('ğŸ”„ åœæ­¢éŒ„éŸ³ä½†ä¿æŒéŸ³é »è³‡æºæ´»èº');
  };

  const stopRecording = () => {
    console.log('ğŸ¬ stopRecording è¢«èª¿ç”¨');
    
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      console.log('ğŸ“¹ åœæ­¢ MediaRecorder');
      mediaRecorderRef.current.stop();
    } else {
      console.log('âš ï¸ MediaRecorder ä¸åœ¨éŒ„éŸ³ç‹€æ…‹:', mediaRecorderRef.current?.state);
    }
    
    stopListening();
  };

  const endConversation = () => {
    setConversationStarted(false);
    stopRecording();
    stopSpeaking(); // åœæ­¢TTSæ’­æ”¾
    setMessages([]);
    
    // å°è©±çµæŸæ™‚æ‰çœŸæ­£é—œé–‰æ‰€æœ‰éŸ³é »è³‡æº
    if (audioStreamRef.current) {
      audioStreamRef.current.getTracks().forEach(track => track.stop());
      audioStreamRef.current = null;
    }
    
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
    }
    
    // æ¸…ç†å¼•ç”¨
    analyserRef.current = null;
    audioContextRef.current = null;
    streamRef.current = null;
    
    console.log('ğŸ›‘ å°è©±çµæŸï¼Œæ‰€æœ‰éŸ³é »è³‡æºå·²æ¸…ç†');
  };

  const startConversation = async () => {
    await calibrateEnvironmentalNoise();
    setTimeout(() => {
      startListening();
    }, 500);
  };

  const processAudio = async () => {
    setLoading(true);
    setError(null);

    try {
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
      
      if (audioBlob.size < 1000) {
        setLoading(false);
        return;
      }

      // å…ˆæ·»åŠ ä¸€å€‹ç”¨æˆ¶æ¶ˆæ¯ï¼ˆloadingç‹€æ…‹ï¼‰
      const userMessageId = `user_${Date.now()}`;
      const userMessage: Message = {
        id: userMessageId,
        type: 'user',
        content: 'æ­£åœ¨è½‰éŒ„èªéŸ³...',
        timestamp: new Date(),
        isLoading: true,
      };
      setMessages(prev => [...prev, userMessage]);

      // æ­¥é©Ÿ1ï¼šèªéŸ³è½‰éŒ„
      const formData = new FormData();
      formData.append('audio', audioBlob, 'audio.webm');

      const transcribeResponse = await axios.post('/api/transcribe', formData, {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
        timeout: 30000,
      });

      const { transcript } = transcribeResponse.data;

      // æ›´æ–°ç”¨æˆ¶æ¶ˆæ¯çš„è½‰éŒ„çµæœ
      setMessages(prev => prev.map(msg => 
        msg.id === userMessageId 
          ? { ...msg, content: transcript, isLoading: false }
          : msg
      ));

      // å¦‚æœè½‰éŒ„çµæœç‚ºç©ºï¼Œä¸é€²è¡ŒAIå›è¦†
      if (!transcript.trim() || transcript === 'ï¼ˆæœªè­˜åˆ¥åˆ°èªéŸ³ï¼‰') {
        setLoading(false);
        return;
      }

      // æ­¥é©Ÿ4ï¼šæ·»åŠ AIå›è¦†æ¶ˆæ¯ï¼ˆloadingç‹€æ…‹ï¼‰
      const aiMessageId = `ai_${Date.now()}`;
      const aiMessage: Message = {
        id: aiMessageId,
        type: 'ai',
        content: 'æ­£åœ¨æ€è€ƒå›è¦†...',
        timestamp: new Date(),
        isLoading: true,
      };
      setMessages(prev => [...prev, aiMessage]);

      // æ­¥é©Ÿ3ï¼šæ§‹å»ºå°è©±æ­·å²ï¼ˆä¸åŒ…å«ç•¶å‰å°è©±ï¼‰
      const conversationHistory: ConversationMessage[] = messages
        .filter(msg => !msg.isLoading && msg.content.trim() && msg.content !== 'æ­£åœ¨è½‰éŒ„èªéŸ³...' && msg.content !== 'æ­£åœ¨æ€è€ƒå›è¦†...')
        .slice(-10) // åªä¿ç•™æœ€è¿‘ 10 æ¢æ¶ˆæ¯é¿å…éé•·
        .map(msg => ({
          role: msg.type === 'user' ? 'user' as const : 'assistant' as const,
          content: msg.content
        }));

      console.log('Conversation history:', conversationHistory);

      // æ­¥é©Ÿ4ï¼šç²å–AIå›è¦†
      const replyResponse = await axios.post('/api/reply', {
        message: transcript,
        conversationHistory: conversationHistory,
      }, {
        headers: {
          'Content-Type': 'application/json',
        },
        timeout: 60000,
      });

      const { reply } = replyResponse.data;

      // æ›´æ–°AIæ¶ˆæ¯çš„å›è¦†çµæœ
      setMessages(prev => prev.map(msg => 
        msg.id === aiMessageId 
          ? { ...msg, content: reply, isLoading: false }
          : msg
      ));

      // å¦‚æœå•Ÿç”¨äº†TTSï¼Œè‡ªå‹•æœ—è®€AIå›è¦†
      if (ttsEnabled && reply.trim()) {
        setTimeout(() => {
          speakText(reply, aiMessageId);
        }, 500); // ç¨å¾®å»¶é²ä»¥ç¢ºä¿UIæ›´æ–°å®Œæˆ
      }

    } catch (err) {
      console.error('è™•ç†éŒ¯èª¤:', err);
      setError(err instanceof Error ? err.message : 'è™•ç†å¤±æ•—');
      
      // ç§»é™¤loadingä¸­çš„æ¶ˆæ¯
      setMessages(prev => prev.filter(msg => !msg.isLoading));
    } finally {
      setLoading(false);
    }
  };

  const getVolumeBarColor = () => {
    if (isCalibrating) return '#ffc107';
    if (!isListening) return '#6c757d';
    
    const voiceThreshold = getVoiceThreshold();
    const silenceThreshold = getSilenceThreshold();
    
    if (currentVolume >= voiceThreshold) return '#28a745'; // ç¶ è‰² - èªéŸ³
    if (currentVolume >= silenceThreshold) return '#fd7e14'; // æ©™è‰² - ä¸­ç­‰
    return '#dc3545'; // ç´…è‰² - éœéŸ³
  };

  const getVolumePercentage = () => {
    const maxDisplayVolume = Math.max(getVoiceThreshold() * 2, 100);
    return Math.min((currentVolume / maxDisplayVolume) * 100, 100);
  };

  // éŸ³é‡æª¢æ¸¬å¾ªç’° - ä¿®å¾©é–‰åŒ…å•é¡Œ
  const startVolumeMonitoring = () => {
    console.log('ğŸ”„ startVolumeMonitoring è¢«èª¿ç”¨');
    
    if (volumeCheckIntervalRef.current) {
      console.log('ğŸ›‘ æ¸…é™¤èˆŠçš„éŸ³é‡ç›£æ§');
      clearInterval(volumeCheckIntervalRef.current);
    }

    let checkCount = 0;

    volumeCheckIntervalRef.current = setInterval(() => {
      checkCount++;
      
      // è©³ç´°çš„ç‹€æ…‹æª¢æŸ¥ - ä½¿ç”¨ ref é¿å…é–‰åŒ…å•é¡Œ
      const hasAnalyser = !!analyserRef.current;
      const currentIsListening = isListeningRef.current;
      const audioContextState = audioContextRef.current?.state;
      const streamActive = audioStreamRef.current?.active;
      
      if (!hasAnalyser || !currentIsListening) {
        if (checkCount % 10 === 0) { // æ¯ç§’æ‰“å°ä¸€æ¬¡
          console.log('âš ï¸ éŸ³é‡æª¢æ¸¬æ¢ä»¶ä¸æ»¿è¶³:', { 
            checkCount,
            hasAnalyser, 
            currentIsListening,
            audioContextState,
            streamActive
          });
        }
        return;
      }

      const dataArray = new Uint8Array(analyserRef.current!.frequencyBinCount);
      analyserRef.current!.getByteFrequencyData(dataArray);
      
      // è¨ˆç®—éŸ³é‡
      const sum = Array.from(dataArray).reduce((a, b) => a + b, 0);
      const average = sum / dataArray.length;
      const maxValue = Math.max(...Array.from(dataArray));
      
      setCurrentVolume(average);
      
      // å¦‚æœTTSæ­£åœ¨æ’­æ”¾ï¼Œæ”¶é›†éŸ³é‡æ•¸æ“šç”¨æ–¼å­¸ç¿’
      const ttsPlaying = typeof window !== 'undefined' && speechSynthesis ? speechSynthesis.speaking : false;
      if (ttsPlaying) {
        ttsVolumeSamplesRef.current.push(average);
        setTtsVolumeLevel(average);
        
        // è¨ˆç®—éŸ³é‡è®ŠåŒ–ç‡ï¼Œæª¢æ¸¬çªç„¶çš„éŸ³é‡å¢åŠ 
        const volumeChange = Math.abs(average - previousVolumeRef.current);
        if (volumeChange > 2) { // å¦‚æœéŸ³é‡è®ŠåŒ–è¶…é2ï¼ˆé™ä½é–€æª»ï¼‰
          volumeChangeCountRef.current++;
        }
        previousVolumeRef.current = average;
        
        // ä¿æŒæœ€è¿‘100å€‹æ¨£æœ¬
        if (ttsVolumeSamplesRef.current.length > 100) {
          ttsVolumeSamplesRef.current = ttsVolumeSamplesRef.current.slice(-100);
        }
      } else {
        // TTSåœæ­¢æ™‚é‡ç½®è®ŠåŒ–è¨ˆæ•¸
        volumeChangeCountRef.current = 0;
        previousVolumeRef.current = 0;
      }
      
      const silenceThreshold = getSilenceThreshold();
      const voiceThreshold = getVoiceThreshold();
      
      // æ¯ç§’æ‰“å°ä¸€æ¬¡è©³ç´°ä¿¡æ¯
      if (checkCount % 10 === 0) {
        const avgTtsVolume = ttsVolumeSamplesRef.current.length > 0 
          ? (ttsVolumeSamplesRef.current.reduce((sum, vol) => sum + vol, 0) / ttsVolumeSamplesRef.current.length).toFixed(1)
          : 'N/A';
        console.log(`ğŸ”Š ç¬¬${checkCount}æ¬¡æª¢æŸ¥: å¹³å‡=${average.toFixed(1)}, æœ€å¤§=${maxValue.toFixed(1)}, èªéŸ³é–¾å€¼=${voiceThreshold.toFixed(1)}, TTSæ’­æ”¾=${ttsPlaying}`);
        console.log(`ğŸ“Š éŸ³é »ç‹€æ…‹: ä¸Šä¸‹æ–‡=${audioContextState}, æµæ´»èº=${streamActive}, ç›£è½ä¸­=${currentIsListening}`);
        console.log(`ğŸ“ˆ TTSéŸ³é‡ç›£æ§: ç•¶å‰=${average.toFixed(1)}, å¹³å‡TTSéŸ³é‡=${avgTtsVolume}, æ¨£æœ¬æ•¸=${ttsVolumeSamplesRef.current.length}`);
        const timeSinceStart = Date.now() - ttsStartTime;
        if (ttsPlaying) {
          if (timeSinceStart < 1000) {
            console.log(`ğŸ¯ ä¿è­·æœŸé–¾å€¼: åŸºæº–=${baselineNoiseRef.current}, ä½¿ç”¨é–¾å€¼=${voiceThreshold.toFixed(1)} (TTSé–‹å§‹${timeSinceStart}ms)`);
          } else if (ttsVolumeSamplesRef.current.length > 8) {
            const maxTtsVolume = Math.max(...ttsVolumeSamplesRef.current);
            console.log(`ğŸ¯ å‹•æ…‹é–¾å€¼: åŸºæº–=${baselineNoiseRef.current}, TTSå¹³å‡=${avgTtsVolume}, TTSæœ€å¤§=${maxTtsVolume.toFixed(1)}, è¨ˆç®—é–¾å€¼=${voiceThreshold.toFixed(1)}`);
          } else {
            console.log(`ğŸ¯ ç­‰å¾…æ•¸æ“šé–¾å€¼: åŸºæº–=${baselineNoiseRef.current}, ä½¿ç”¨é–¾å€¼=${voiceThreshold.toFixed(1)} (æ¨£æœ¬æ•¸${ttsVolumeSamplesRef.current.length})`);
          }
        } else {
          console.log(`ğŸ¯ æ­£å¸¸é–¾å€¼: åŸºæº–=${baselineNoiseRef.current}, ä½¿ç”¨é–¾å€¼=${voiceThreshold.toFixed(1)}`);
        }
      }
      
      // èªéŸ³æª¢æ¸¬é‚è¼¯ - åªä¾è³´å¹³å‡å€¼ï¼Œå¿½ç•¥æœ€å¤§å€¼æ³¢å‹•
      const isVoiceDetected = average >= voiceThreshold; // åªä½¿ç”¨å¹³å‡å€¼æª¢æ¸¬
      
      // æ¯æ¬¡éƒ½è¨˜éŒ„èªéŸ³æª¢æ¸¬çµæœï¼ˆç”¨æ–¼èª¿è©¦ï¼‰
      if (checkCount % 5 === 0) { // æ¯500msè¨˜éŒ„ä¸€æ¬¡
        const ttsPlaying = typeof window !== 'undefined' && speechSynthesis ? speechSynthesis.speaking : false;
        const avgTtsVolume = ttsVolumeSamplesRef.current.length > 0 
          ? ttsVolumeSamplesRef.current.reduce((sum, vol) => sum + vol, 0) / ttsVolumeSamplesRef.current.length
          : 0;
        console.log('ğŸ” èªéŸ³æª¢æ¸¬è©³æƒ…:', {
          average: average.toFixed(1),
          maxValue: maxValue.toFixed(1),
          voiceThreshold: voiceThreshold.toFixed(1),
          normalThreshold: (baselineNoiseRef.current + 1).toFixed(1),
          dynamicTtsThreshold: ttsPlaying && ttsVolumeSamplesRef.current.length > 8 
            ? Math.max(avgTtsVolume * 1.6, Math.max(...ttsVolumeSamplesRef.current) * 1.3, baselineNoiseRef.current + 10).toFixed(1)
            : 'N/A',
          fallbackTtsThreshold: (baselineNoiseRef.current + 15).toFixed(1),
          volumeChangeCount: volumeChangeCountRef.current,
          avgTtsVolume: avgTtsVolume.toFixed(1),
          ttsPlaying,
          isVoiceDetectedByAverage: average >= voiceThreshold,
          isVoiceDetected,
          hasDetectedVoiceBefore: hasDetectedVoiceRef.current,
          checkCount
        });
      }
      
      if (isVoiceDetected) {
        // ğŸ”¥ æ ¸å¿ƒåŠŸèƒ½ï¼šå¦‚æœTTSæ­£åœ¨æ’­æ”¾ä¸”æª¢æ¸¬åˆ°èªéŸ³ï¼Œå¢åŠ é¡å¤–é©—è­‰å¾Œåœæ­¢TTS
        if (typeof window !== 'undefined' && speechSynthesis && speechSynthesis.speaking) {
          // é¡å¤–é©—è­‰ï¼šæª¢æŸ¥æ˜¯å¦çœŸçš„æ˜¯äººè²æ‰“æ–·
          const timeSinceStart = Date.now() - ttsStartTime;
          const hasSignificantVolumeChange = volumeChangeCountRef.current > 1; // æœ‰é¡¯è‘—éŸ³é‡è®ŠåŒ–ï¼ˆé™ä½é–€æª»ï¼‰
          const isAboveThreshold = average > getVoiceThreshold(); // è¶…éåŸºæœ¬é–¾å€¼å³å¯
          
          if (timeSinceStart > 500 && (hasSignificantVolumeChange || isAboveThreshold)) {
            console.log('ğŸ”‡ æª¢æ¸¬åˆ°ç”¨æˆ¶èªªè©±ï¼Œç«‹å³åœæ­¢TTSæ’­æ”¾', {
              timeSinceStart,
              hasSignificantVolumeChange,
              isAboveThreshold,
              currentVolume: average.toFixed(1),
              threshold: getVoiceThreshold().toFixed(1)
            });
            stopSpeaking();
          } else {
            console.log('âš ï¸ ç–‘ä¼¼èª¤åˆ¤ï¼Œä¸åœæ­¢TTS', {
              timeSinceStart,
              hasSignificantVolumeChange,
              isAboveThreshold,
              volumeChangeCount: volumeChangeCountRef.current
            });
          }
        }
        
        if (!hasDetectedVoiceRef.current) {
          console.log('ğŸŸ¢ æª¢æ¸¬åˆ°èªéŸ³ï¼', { 
            average: average.toFixed(1), 
            max: maxValue.toFixed(1),
            trigger: average >= voiceThreshold ? 'average' : 'maxValue',
            ttsWasPlaying: speechSynthesis.speaking
          });
          setHasDetectedVoice(true);
          hasDetectedVoiceRef.current = true;
        }
        
        // æ¸…é™¤éœéŸ³è¨ˆæ™‚å™¨
        if (silenceTimerRef.current) {
          clearTimeout(silenceTimerRef.current);
          silenceTimerRef.current = null;
          console.log('ğŸ”„ æª¢æ¸¬åˆ°èªéŸ³ï¼Œå–æ¶ˆéœéŸ³å€’æ•¸');
        }
      } else if (hasDetectedVoiceRef.current) {
        // ä¿®æ”¹ï¼šåªè¦æª¢æ¸¬åˆ°èªéŸ³å¾Œï¼ŒéŸ³é‡ä½æ–¼èªéŸ³é–¾å€¼å°±é–‹å§‹éœéŸ³å€’æ•¸
        if (!silenceTimerRef.current) {
          console.log('ğŸ”´ é–‹å§‹éœéŸ³å€’æ•¸...', { 
            currentVolume: average.toFixed(1), 
            voiceThreshold: voiceThreshold.toFixed(1),
            silenceThreshold: silenceThreshold.toFixed(1),
            checkCount,
            timestamp: new Date().toISOString()
          });
          
          silenceTimerRef.current = setTimeout(() => {
            console.log('â° éœéŸ³æ™‚é–“åˆ°ï¼Œæº–å‚™è‡ªå‹•ç™¼é€éŒ„éŸ³', {
              timestamp: new Date().toISOString(),
              isListening: isListeningRef.current,
              mediaRecorderState: mediaRecorderRef.current?.state
            });
            
            // ç¢ºä¿åœ¨åŸ·è¡Œå‰æ¸…ç†è¨ˆæ™‚å™¨å¼•ç”¨
            silenceTimerRef.current = null;
            
            try {
              stopRecording();
              console.log('âœ… stopRecording åŸ·è¡Œå®Œæˆ');
            } catch (error) {
              console.error('âŒ stopRecording åŸ·è¡ŒéŒ¯èª¤:', error);
            }
          }, SILENCE_DURATION);
          
          console.log('ğŸ• éœéŸ³è¨ˆæ™‚å™¨å·²è¨­ç½®ï¼ŒID:', silenceTimerRef.current);
        } else {
          // æ¯ç§’æ‰“å°ä¸€æ¬¡è¨ˆæ™‚å™¨ç‹€æ…‹
          if (checkCount % 10 === 0) {
            console.log('â³ éœéŸ³è¨ˆæ™‚å™¨é‹è¡Œä¸­...', {
              timerId: silenceTimerRef.current,
              remainingTime: `ç´„ ${Math.ceil((SILENCE_DURATION - ((checkCount % 30) * 100)) / 1000)}ç§’`,
              checkCount
            });
          }
        }
      }
    }, 100);
    
    console.log('âœ… éŸ³é‡ç›£æ§å®šæ™‚å™¨å·²è¨­ç½®ï¼ŒID:', volumeCheckIntervalRef.current);
  };

  const stopVolumeMonitoring = () => {
    if (volumeCheckIntervalRef.current) {
      clearInterval(volumeCheckIntervalRef.current);
      volumeCheckIntervalRef.current = null;
    }
  };

  const formatTime = (date: Date) => {
    return date.toLocaleTimeString('zh-TW', { 
      hour: '2-digit', 
      minute: '2-digit' 
    });
  };

  return (
    <div style={{ 
      display: 'flex', 
      flexDirection: 'column', 
      height: '100vh', 
      maxWidth: '800px', 
      margin: '0 auto',
      padding: '1rem'
    }}>
      <h1>æœ¬åœ°èªéŸ³ AI åŠ©æ‰‹ ğŸ§ </h1>
      <p style={{ color: '#666', marginBottom: '1rem' }}>
        æ™ºæ…§å°è©±è¨˜æ†¶ + çœŸäººåŒ–å›æ‡‰ã€‚è‡ªå‹•æ ¡æº–ç’°å¢ƒéŸ³ï¼Œæ™ºæ…§æª¢æ¸¬èªéŸ³æ´»å‹•ã€‚AI æœƒè¨˜ä½å°è©±å…§å®¹ï¼Œå›æ‡‰å¾Œè‡ªå‹•é‡æ–°é–‹å§‹éŒ„éŸ³ã€‚
      </p>
      
      {/* éŸ³é‡ç›£æ§ */}
      <div style={{ marginBottom: '1rem', padding: '1rem', backgroundColor: '#f8f9fa', borderRadius: '8px' }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', marginBottom: '0.5rem' }}>
          <span style={{ fontSize: '0.9rem', color: '#666' }}>éŸ³é‡ç›£æ§</span>
                      <span style={{ fontSize: '0.8rem', color: '#666' }}>
              ç•¶å‰: {currentVolume.toFixed(1)}
              {isSpeaking && ttsVolumeLevel > 0 && (
                <span style={{ marginLeft: '10px', color: '#9c27b0' }}>
                  | TTSéŸ³é‡: {ttsVolumeLevel.toFixed(1)}
                </span>
              )}
            </span>
        </div>
        <div style={{ 
          width: '100%', 
          height: '8px', 
          backgroundColor: '#e9ecef', 
          borderRadius: '4px',
          overflow: 'hidden'
        }}>
          <div style={{
            width: `${getVolumePercentage()}%`,
            height: '100%',
            backgroundColor: getVolumeBarColor(),
            transition: 'all 0.1s ease'
          }} />
        </div>
        {(isListening || isCalibrating) && (
          <div style={{ fontSize: '0.8rem', color: '#666', marginTop: '0.5rem' }}>
            éœéŸ³é–¾å€¼: {getSilenceThreshold().toFixed(1)} | èªéŸ³é–¾å€¼: {getVoiceThreshold().toFixed(1)}
            {isSpeaking && (
              <span style={{ color: '#9c27b0', marginLeft: '10px' }}>
                ğŸ—£ï¸ TTSæ¨¡å¼ï¼ˆå‹•æ…‹é–¾å€¼:{getVoiceThreshold().toFixed(1)}ï¼‰
              </span>
            )}
            {hasDetectedVoice && (
              <span style={{ color: '#28a745', marginLeft: '10px' }}>âœ… èªéŸ³å·²æª¢æ¸¬</span>
            )}
          </div>
        )}
      </div>

      {/* TTS è¨­ç½® */}
      <div style={{ marginBottom: '1rem', padding: '1rem', backgroundColor: '#e3f2fd', borderRadius: '8px', display: 'none' }}>
        <div style={{ display: 'flex', alignItems: 'center', gap: '1rem', flexWrap: 'wrap' }}>
          <div style={{ display: 'flex', alignItems: 'center', gap: '0.5rem' }}>
            <input
              type="checkbox"
              id="tts-enabled"
              checked={ttsEnabled}
              onChange={(e) => setTtsEnabled(e.target.checked)}
            />
            <label htmlFor="tts-enabled" style={{ fontSize: '0.9rem', color: '#666' }}>
              ğŸ—£ï¸ è‡ªå‹•æœ—è®€
            </label>
          </div>

          {availableVoices.length > 0 && (
            <div style={{ display: 'flex', alignItems: 'center', gap: '0.5rem' }}>
              <label style={{ fontSize: '0.9rem', color: '#666' }}>èªéŸ³:</label>
              <select
                value={ttsVoice?.name || ''}
                onChange={(e) => {
                  const voice = availableVoices.find(v => v.name === e.target.value);
                  setTtsVoice(voice || null);
                }}
                style={{ fontSize: '0.8rem', padding: '0.25rem' }}
              >
                {availableVoices.map((voice) => (
                  <option key={voice.name} value={voice.name}>
                    {voice.name} ({voice.lang})
                  </option>
                ))}
              </select>
            </div>
          )}

          <div style={{ display: 'flex', alignItems: 'center', gap: '0.5rem' }}>
            <label style={{ fontSize: '0.9rem', color: '#666' }}>èªé€Ÿ:</label>
            <input
              type="range"
              min="0.5"
              max="2"
              step="0.1"
              value={ttsRate}
              onChange={(e) => setTtsRate(parseFloat(e.target.value))}
              style={{ width: '60px' }}
            />
            <span style={{ fontSize: '0.8rem', color: '#666', minWidth: '30px' }}>
              {ttsRate.toFixed(1)}x
            </span>
          </div>

          <div style={{ display: 'flex', alignItems: 'center', gap: '0.5rem' }}>
            <label style={{ fontSize: '0.9rem', color: '#666' }}>éŸ³é‡:</label>
            <input
              type="range"
              min="0"
              max="1"
              step="0.1"
              value={ttsVolume}
              onChange={(e) => setTtsVolume(parseFloat(e.target.value))}
              style={{ width: '60px' }}
            />
            <span style={{ fontSize: '0.8rem', color: '#666', minWidth: '30px' }}>
              {Math.round(ttsVolume * 100)}%
            </span>
          </div>

          {isSpeaking && (
            <button
              onClick={stopSpeaking}
              style={{
                padding: '0.25rem 0.5rem',
                fontSize: '0.8rem',
                backgroundColor: '#dc3545',
                color: 'white',
                border: 'none',
                borderRadius: '4px',
                cursor: 'pointer',
              }}
            >
              ğŸ”‡ åœæ­¢æœ—è®€
            </button>
          )}
        </div>
      </div>
      
      {/* æ§åˆ¶æŒ‰éˆ• */}
      <div style={{ marginBottom: '1rem' }}>
        {isCalibrating ? (
          <div style={{ textAlign: 'center' }}>
            <button
              disabled
              style={{
                padding: '1rem 2rem',
                fontSize: '1.2rem',
                backgroundColor: '#ffc107',
                color: 'white',
                border: 'none',
                borderRadius: '8px',
                cursor: 'not-allowed',
              }}
            >
              ğŸ”§ æ ¡æº–ç’°å¢ƒéŸ³ä¸­... {Math.round(calibrationProgress)}%
            </button>
            <div style={{ 
              marginTop: '1rem', 
              padding: '0.5rem', 
              backgroundColor: '#fff3cd', 
              borderRadius: '4px',
              fontSize: '0.9rem',
              color: '#856404'
            }}>
              è«‹ä¿æŒå®‰éœ {Math.ceil((CALIBRATION_DURATION - (calibrationProgress / 100 * CALIBRATION_DURATION)) / 1000)} ç§’ï¼Œè®“ç³»çµ±å­¸ç¿’ç’°å¢ƒéŸ³...
            </div>
          </div>
        ) : !conversationStarted ? (
          <button
            onClick={startConversation}
            disabled={loading}
            style={{
              padding: '1rem 2rem',
              fontSize: '1.2rem',
              backgroundColor: loading ? '#6c757d' : '#28a745',
              color: 'white',
              border: 'none',
              borderRadius: '8px',
              cursor: loading ? 'not-allowed' : 'pointer',
            }}
          >
            ğŸ™ï¸ æ ¡æº–ä¸¦é–‹å§‹å°è©±
          </button>
        ) : (
          <div style={{ display: 'flex', gap: '1rem', alignItems: 'center' }}>
            <button
              onClick={isListening ? stopRecording : startListening}
              disabled={loading}
              style={{
                padding: '1rem 2rem',
                fontSize: '1.2rem',
                backgroundColor: isListening ? '#dc3545' : loading ? '#6c757d' : '#007bff',
                color: 'white',
                border: 'none',
                borderRadius: '8px',
                cursor: loading ? 'not-allowed' : 'pointer',
                position: 'relative',
                animation: isListening ? 'pulse 1s infinite' : 'none',
              }}
            >
              {loading ? 'è™•ç†ä¸­...' : isListening ? 'ğŸ¤ æ­£åœ¨è†è½...' : 'ğŸ™ï¸ ç¹¼çºŒéŒ„éŸ³'}
            </button>
            
            <button
              onClick={endConversation}
              style={{
                padding: '1rem 1.5rem',
                fontSize: '1rem',
                backgroundColor: '#6c757d',
                color: 'white',
                border: 'none',
                borderRadius: '8px',
                cursor: 'pointer',
              }}
            >
              ğŸ›‘ çµæŸå°è©±
            </button>

            <button
              onClick={calibrateEnvironmentalNoise}
              disabled={isListening || loading}
              style={{
                padding: '1rem 1.5rem',
                fontSize: '1rem',
                backgroundColor: '#ffc107',
                color: 'white',
                border: 'none',
                borderRadius: '8px',
                cursor: (isListening || loading) ? 'not-allowed' : 'pointer',
              }}
            >
              ğŸ”§ é‡æ–°æ ¡æº–
            </button>
          </div>
        )}
        
        {isListening && (
          <div style={{ 
            marginTop: '1rem', 
            padding: '0.5rem', 
            backgroundColor: hasDetectedVoice ? '#d4edda' : '#fff3cd', 
            borderRadius: '4px',
            fontSize: '0.9rem',
            color: hasDetectedVoice ? '#155724' : '#856404'
          }}>
            {hasDetectedVoice 
              ? `ğŸŸ¢ å·²æª¢æ¸¬åˆ°èªéŸ³ï¼Œåœæ­¢èªªè©± ${SILENCE_DURATION/1000} ç§’å¾Œæœƒè‡ªå‹•ç™¼é€...` 
              : `ğŸŸ¡ ç­‰å¾…èªéŸ³è¼¸å…¥...ï¼ˆç•¶å‰éŸ³é‡: ${currentVolume.toFixed(1)}, éœ€è¦è¶…é: ${getVoiceThreshold().toFixed(1)}ï¼‰`
            }
            {isSpeaking && !hasDetectedVoice && (
              <div style={{ marginTop: '0.3rem', fontSize: '0.8rem', color: '#28a745' }}>
                ğŸ’¡ TTSæ­£åœ¨æ’­æ”¾ï¼Œè«‹ç¨å¾®å¤§è²èªªè©±ä¾†æ‰“æ–·ï¼ˆå‹•æ…‹é–¾å€¼: {getVoiceThreshold().toFixed(1)}ï¼‰
                <br />
                <span style={{ color: '#9c27b0' }}>
                  ğŸ”Š å¯¦æ™‚ï¼šTTSéŸ³é‡{ttsVolumeLevel.toFixed(1)}ï¼Œç³»çµ±å·²è‡ªå‹•èª¿æ•´æª¢æ¸¬é–¾å€¼
                  {ttsVolumeSamplesRef.current.length > 5 && (
                    <span>ï¼ˆåŸºæ–¼{ttsVolumeSamplesRef.current.length}å€‹æ¨£æœ¬ï¼‰</span>
                  )}
                </span>
              </div>
            )}
          </div>
        )}

        {conversationStarted && !isListening && !loading && (
          <div style={{ 
            marginTop: '1rem', 
            padding: '0.5rem', 
            backgroundColor: '#d1ecf1', 
            borderRadius: '4px',
            fontSize: '0.9rem',
            color: '#0c5460'
          }}>
            ğŸ”„ AI å›æ‡‰å®Œæˆå¾Œæœƒè‡ªå‹•é‡æ–°é–‹å§‹éŒ„éŸ³...
            {isSpeaking && (
              <span style={{ marginLeft: '10px', color: '#28a745' }}>
                ğŸ—£ï¸ TTSæ’­æ”¾ä¸­ï¼Œæ‚¨å¯éš¨æ™‚èªªè©±æ‰“æ–·
              </span>
            )}
          </div>
        )}
      </div>

      {error && (
        <div style={{
          padding: '1rem',
          backgroundColor: '#f8d7da',
          color: '#721c24',
          borderRadius: '4px',
          marginBottom: '1rem'
        }}>
          éŒ¯èª¤ï¼š{error}
        </div>
      )}

      {/* èŠå¤©è¨˜éŒ„å€åŸŸ */}
      <div style={{ 
        flex: 1, 
        backgroundColor: '#f8f9fa', 
        borderRadius: '8px', 
        padding: '1rem', 
        overflow: 'auto',
        display: 'flex',
        flexDirection: 'column',
        gap: '1rem'
      }}>
        {messages.length === 0 && conversationStarted && (
          <div style={{ 
            textAlign: 'center', 
            color: '#666', 
            fontStyle: 'italic',
            marginTop: '2rem'
          }}>
            ğŸ¤ é–‹å§‹èªªè©±ä¾†é€²è¡Œå°è©±...
          </div>
        )}

        {messages.map((message) => (
          <div
            key={message.id}
            style={{
              display: 'flex',
              justifyContent: message.type === 'user' ? 'flex-end' : 'flex-start',
              marginBottom: '1rem'
            }}
          >
                          <div
                style={{
                  maxWidth: '70%',
                  padding: '1rem',
                  borderRadius: '12px',
                  backgroundColor: message.type === 'user' ? '#007bff' : '#e9ecef',
                  color: message.type === 'user' ? 'white' : '#333',
                  position: 'relative',
                  opacity: message.isLoading ? 0.7 : 1,
                }}
              >
                <div style={{ 
                  fontSize: '0.8rem', 
                  opacity: 0.8, 
                  marginBottom: '0.5rem',
                  display: 'flex',
                  alignItems: 'center',
                  gap: '0.5rem'
                }}>
                  <span>{message.type === 'user' ? 'ğŸ—£ï¸ ä½ ' : 'ğŸ¤– AI'}</span>
                  <span>{formatTime(message.timestamp)}</span>
                  {message.isLoading && <span>â³</span>}
                  {message.isPlaying && <span>ğŸ”Š</span>}
                  
                  {/* AIæ¶ˆæ¯çš„æ’­æ”¾æŒ‰éˆ• */}
                  {message.type === 'ai' && !message.isLoading && message.content.trim() && (
                    <button
                      onClick={() => {
                        if (message.isPlaying) {
                          stopSpeaking();
                        } else {
                          speakText(message.content, message.id);
                        }
                      }}
                      style={{
                        padding: '0.2rem 0.4rem',
                        fontSize: '0.7rem',
                        backgroundColor: message.isPlaying ? '#dc3545' : '#28a745',
                        color: 'white',
                        border: 'none',
                        borderRadius: '3px',
                        cursor: 'pointer',
                        opacity: 0.8,
                      }}
                    >
                      {message.isPlaying ? 'ğŸ”‡' : 'ğŸ”Š'}
                    </button>
                  )}
                </div>
                <div style={{ fontSize: '1rem', lineHeight: '1.4' }}>
                  {message.content}
                </div>
              </div>
          </div>
        ))}
        <div ref={messagesEndRef} />
      </div>

      <div style={{ marginTop: '1rem', fontSize: '0.9rem', color: '#666' }}>
        <p>âœ… æ™ºæ…§ç’°å¢ƒéŸ³æ ¡æº–ï¼Œå¯é çš„éŸ³é‡æª¢æ¸¬</p>
        <p>âœ… ä½¿ç”¨ Whisper Small æ¨¡å‹é€²è¡Œä¸­æ–‡èªéŸ³è¾¨è­˜</p>
        <p>âœ… é€£æ¥åˆ° Gemma3:1b æ¨¡å‹ç”Ÿæˆå›è¦†</p>
        <p>ğŸ—£ï¸ ä½¿ç”¨ç€è¦½å™¨åŸç”Ÿ Web Speech API é€²è¡ŒèªéŸ³åˆæˆ</p>
        <p>ğŸ”„ AI å›æ‡‰å¾Œè‡ªå‹•é‡æ–°é–‹å§‹éŒ„éŸ³ï¼Œå¯¦ç¾é€£çºŒå°è©±</p>
        <p>ğŸ§  æ™ºæ…§å°è©±è¨˜æ†¶ï¼šAI æœƒè¨˜ä½æœ€è¿‘çš„å°è©±å…§å®¹ï¼Œè®“äº¤è«‡æ›´è‡ªç„¶</p>
        <p>ğŸ­ çœŸäººåŒ–å›æ‡‰ï¼šä½¿ç”¨å°ˆé–€çš„æç¤ºè©è®“ AI å›ç­”æ›´åƒçœŸäººå°è©±</p>
      </div>

      <style jsx>{`
        @keyframes pulse {
          0% { transform: scale(1); }
          50% { transform: scale(1.05); }
          100% { transform: scale(1); }
        }
      `}</style>
    </div>
  );
} 